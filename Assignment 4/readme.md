<h1> Architectural Basics <h1>

  
  1.  Kernels and how do we decide the number of kernels?
  2.  3x3 Convolutions,
  3.  How many layers,
  4.  Receptive Field,
  5.  MaxPooling,
  6.  Position of MaxPooling,
  7.  1x1 Convolutions,
  8.  SoftMax,
  9.  Learning Rate,
  10. Concept of Transition Layers,
  11. Position of Transition Layer,
  12. Batch Normalization,
  13. Image Normalization,
  14. Number of Epochs and when to increase them,
  15. DropOut
  16. When do we introduce DropOut, or when do we know we have some overfitting,
  17. The distance of MaxPooling from Prediction,
  18. The distance of Batch Normalization from Prediction,
  19. How do we know our network is not going well, comparatively, very early
  20. Batch Size, and effects of batch size
  21. When to add validation checks
  22. LR schedule and concept behind it
  23. Adam vs. SGD
  24. When do we stop convolutions and go ahead with a larger kernel or some other alternative (which we have not yet covered)
